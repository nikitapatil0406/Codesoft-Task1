{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Importing the biraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
        "from keras.optimizers import SGD\n",
        "import math\n",
        "from sklearn.matrics import mean_squared_error\n"
      ],
      "metadata": {
        "id": "RyBxo4N8vrYW",
        "outputId": "7a55508a-dada-4b0b-860e-2acbc3269ba6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn.matrics'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-dbac811469de>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.matrics'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HmgLHAbgvrBu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3HX5_s4vC61"
      },
      "source": [
        "# Working with RNNs\n",
        "\n",
        "**Authors:** Scott Zhu, Francois Chollet<br>\n",
        "**Date created:** 2019/07/08<br>\n",
        "**Last modified:** 2023/07/10<br>\n",
        "**Description:** Complete guide to using & customizing RNN layers."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Fvz6I6l1vXJK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_srJD7nFvC65"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Recurrent neural networks (RNN) are a class of neural networks that is powerful for\n",
        "modeling sequence data such as time series or natural language.\n",
        "\n",
        "Schematically, a RNN layer uses a `for` loop to iterate over the timesteps of a\n",
        "sequence, while maintaining an internal state that encodes information about the\n",
        "timesteps it has seen so far.\n",
        "\n",
        "The Keras RNN API is designed with a focus on:\n",
        "\n",
        "- **Ease of use**: the built-in `keras.layers.RNN`, `keras.layers.LSTM`,\n",
        "`keras.layers.GRU` layers enable you to quickly build recurrent models without\n",
        "having to make difficult configuration choices.\n",
        "\n",
        "- **Ease of customization**: You can also define your own RNN cell layer (the inner\n",
        "part of the `for` loop) with custom behavior, and use it with the generic\n",
        "`keras.layers.RNN` layer (the `for` loop itself). This allows you to quickly\n",
        "prototype different research ideas in a flexible way with minimal code."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KlD2Vjd02yWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/content/AABA_2006-01-01_to_2018-01-01.csv')\n",
        "dataset.info()\n",
        "dataset"
      ],
      "metadata": {
        "id": "11FyHthJvUp5",
        "outputId": "7e545846-10ba-4b74-8252-f369508736a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3019 entries, 0 to 3018\n",
            "Data columns (total 7 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Date    3019 non-null   object \n",
            " 1   Open    3019 non-null   float64\n",
            " 2   High    3019 non-null   float64\n",
            " 3   Low     3019 non-null   float64\n",
            " 4   Close   3019 non-null   float64\n",
            " 5   Volume  3019 non-null   int64  \n",
            " 6   Name    3019 non-null   object \n",
            "dtypes: float64(4), int64(1), object(2)\n",
            "memory usage: 165.2+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Date   Open   High    Low  Close    Volume  Name\n",
              "0     2006-01-03  39.69  41.22  38.79  40.91  24232729  AABA\n",
              "1     2006-01-04  41.22  41.90  40.77  40.97  20553479  AABA\n",
              "2     2006-01-05  40.93  41.73  40.85  41.53  12829610  AABA\n",
              "3     2006-01-06  42.88  43.57  42.80  43.21  29422828  AABA\n",
              "4     2006-01-09  43.10  43.66  42.82  43.42  16268338  AABA\n",
              "...          ...    ...    ...    ...    ...       ...   ...\n",
              "3014  2017-12-22  71.42  71.87  71.22  71.58  10979165  AABA\n",
              "3015  2017-12-26  70.94  71.39  69.63  69.86   8542802  AABA\n",
              "3016  2017-12-27  69.77  70.49  69.69  70.06   6345124  AABA\n",
              "3017  2017-12-28  70.12  70.32  69.51  69.82   7556877  AABA\n",
              "3018  2017-12-29  69.79  70.13  69.43  69.85   6613070  AABA\n",
              "\n",
              "[3019 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fda93486-5418-420c-bf10-50fa1258323a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2006-01-03</td>\n",
              "      <td>39.69</td>\n",
              "      <td>41.22</td>\n",
              "      <td>38.79</td>\n",
              "      <td>40.91</td>\n",
              "      <td>24232729</td>\n",
              "      <td>AABA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2006-01-04</td>\n",
              "      <td>41.22</td>\n",
              "      <td>41.90</td>\n",
              "      <td>40.77</td>\n",
              "      <td>40.97</td>\n",
              "      <td>20553479</td>\n",
              "      <td>AABA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2006-01-05</td>\n",
              "      <td>40.93</td>\n",
              "      <td>41.73</td>\n",
              "      <td>40.85</td>\n",
              "      <td>41.53</td>\n",
              "      <td>12829610</td>\n",
              "      <td>AABA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2006-01-06</td>\n",
              "      <td>42.88</td>\n",
              "      <td>43.57</td>\n",
              "      <td>42.80</td>\n",
              "      <td>43.21</td>\n",
              "      <td>29422828</td>\n",
              "      <td>AABA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2006-01-09</td>\n",
              "      <td>43.10</td>\n",
              "      <td>43.66</td>\n",
              "      <td>42.82</td>\n",
              "      <td>43.42</td>\n",
              "      <td>16268338</td>\n",
              "      <td>AABA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3014</th>\n",
              "      <td>2017-12-22</td>\n",
              "      <td>71.42</td>\n",
              "      <td>71.87</td>\n",
              "      <td>71.22</td>\n",
              "      <td>71.58</td>\n",
              "      <td>10979165</td>\n",
              "      <td>AABA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3015</th>\n",
              "      <td>2017-12-26</td>\n",
              "      <td>70.94</td>\n",
              "      <td>71.39</td>\n",
              "      <td>69.63</td>\n",
              "      <td>69.86</td>\n",
              "      <td>8542802</td>\n",
              "      <td>AABA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3016</th>\n",
              "      <td>2017-12-27</td>\n",
              "      <td>69.77</td>\n",
              "      <td>70.49</td>\n",
              "      <td>69.69</td>\n",
              "      <td>70.06</td>\n",
              "      <td>6345124</td>\n",
              "      <td>AABA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3017</th>\n",
              "      <td>2017-12-28</td>\n",
              "      <td>70.12</td>\n",
              "      <td>70.32</td>\n",
              "      <td>69.51</td>\n",
              "      <td>69.82</td>\n",
              "      <td>7556877</td>\n",
              "      <td>AABA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3018</th>\n",
              "      <td>2017-12-29</td>\n",
              "      <td>69.79</td>\n",
              "      <td>70.13</td>\n",
              "      <td>69.43</td>\n",
              "      <td>69.85</td>\n",
              "      <td>6613070</td>\n",
              "      <td>AABA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3019 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fda93486-5418-420c-bf10-50fa1258323a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fda93486-5418-420c-bf10-50fa1258323a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fda93486-5418-420c-bf10-50fa1258323a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-60c0db93-bfa2-45bc-8ed8-c7421752aac3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-60c0db93-bfa2-45bc-8ed8-c7421752aac3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-60c0db93-bfa2-45bc-8ed8-c7421752aac3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2a4804e7-e4a9-4a65-8abd-b580d5a75bc3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2a4804e7-e4a9-4a65-8abd-b580d5a75bc3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dataset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 3019,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 3019,\n        \"samples\": [\n          \"2011-08-11\",\n          \"2012-03-20\",\n          \"2006-10-23\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.257241924440622,\n        \"min\": 9.1,\n        \"max\": 73.02,\n        \"num_unique_values\": 1913,\n        \"samples\": [\n          34.67,\n          26.41,\n          66.26\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.356691549246193,\n        \"min\": 9.48,\n        \"max\": 73.25,\n        \"num_unique_values\": 1921,\n        \"samples\": [\n          19.63,\n          37.84,\n          12.27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.157325947582661,\n        \"min\": 8.94,\n        \"max\": 72.46,\n        \"num_unique_values\": 1910,\n        \"samples\": [\n          36.56,\n          32.54,\n          65.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.258163236301503,\n        \"min\": 8.95,\n        \"max\": 72.93,\n        \"num_unique_values\": 1960,\n        \"samples\": [\n          27.34,\n          13.92,\n          28.09\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19262307,\n        \"min\": 1939061,\n        \"max\": 438231658,\n        \"num_unique_values\": 3018,\n        \"samples\": [\n          13301365,\n          30997807,\n          23239286\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"AABA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LHrtLRMk2zoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checking for missing values\n",
        "#training_set = dataset['2016':].iloc[:,1:2].values\n",
        "#test_set = dataset['2017':].iloc[:,1:2].values\n",
        "# Assuming the 'Date' column is of type string and formatted as 'YYYY-MM-DD'\n",
        "training_set = dataset[dataset['Date'] < '2017-01-01'].iloc[:, 1:2].values\n",
        "test_set = dataset[dataset['Date'] >= '2017-01-01'].iloc[:, 1:2].values"
      ],
      "metadata": {
        "id": "zY0Zm0qy3LRv"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6kTnl5N8vC66"
      },
      "outputs": [],
      "source": [
        "#\n",
        "dataset[\"High\"][:'2016'].plot(figsize=(16,4),legend=true)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_k-Uy7wvC66"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5GZ1RxVvC68"
      },
      "source": [
        "## Built-in RNN layers: a simple example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOEU3lA0vC68"
      },
      "source": [
        "There are three built-in RNN layers in Keras:\n",
        "\n",
        "1. `keras.layers.SimpleRNN`, a fully-connected RNN where the output from previous\n",
        "timestep is to be fed to next timestep.\n",
        "\n",
        "2. `keras.layers.GRU`, first proposed in\n",
        "[Cho et al., 2014](https://arxiv.org/abs/1406.1078).\n",
        "\n",
        "3. `keras.layers.LSTM`, first proposed in\n",
        "[Hochreiter & Schmidhuber, 1997](https://www.bioinf.jku.at/publications/older/2604.pdf).\n",
        "\n",
        "In early 2015, Keras had the first reusable open-source Python implementations of LSTM\n",
        "and GRU.\n",
        "\n",
        "Here is a simple example of a `Sequential` model that processes sequences of integers,\n",
        "embeds each integer into a 64-dimensional vector, then processes the sequence of\n",
        "vectors using a `LSTM` layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "alafLJEbvC68",
        "outputId": "c56b21c4-d590-4242-961c-ced43bf94479",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = keras.Sequential()\n",
        "# Add an Embedding layer expecting input vocab of size 1000, and\n",
        "# output embedding dimension of size 64.\n",
        "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
        "\n",
        "# Add a LSTM layer with 128 internal units.\n",
        "model.add(layers.LSTM(128))\n",
        "\n",
        "# Add a Dense layer with 10 units.\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xia7AzQIvC69"
      },
      "source": [
        "Built-in RNNs support a number of useful features:\n",
        "\n",
        "- Recurrent dropout, via the `dropout` and `recurrent_dropout` arguments\n",
        "- Ability to process an input sequence in reverse, via the `go_backwards` argument\n",
        "- Loop unrolling (which can lead to a large speedup when processing short sequences on\n",
        "CPU), via the `unroll` argument\n",
        "- ...and more.\n",
        "\n",
        "For more information, see the\n",
        "[RNN API documentation](https://keras.io/api/layers/recurrent_layers/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJgL6LpavC69"
      },
      "source": [
        "## Outputs and states\n",
        "\n",
        "By default, the output of a RNN layer contains a single vector per sample. This vector\n",
        "is the RNN cell output corresponding to the last timestep, containing information\n",
        "about the entire input sequence. The shape of this output is `(batch_size, units)`\n",
        "where `units` corresponds to the `units` argument passed to the layer's constructor.\n",
        "\n",
        "A RNN layer can also return the entire sequence of outputs for each sample (one vector\n",
        "per timestep per sample), if you set `return_sequences=True`. The shape of this output\n",
        "is `(batch_size, timesteps, units)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZQ-WI0dhvC6-",
        "outputId": "923cdc21-14a2-4cb3-cde0-277c1fa0a626",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
        "\n",
        "# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n",
        "model.add(layers.GRU(256, return_sequences=True))\n",
        "\n",
        "# The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n",
        "model.add(layers.SimpleRNN(128))\n",
        "\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFVGMpglvC6-"
      },
      "source": [
        "In addition, a RNN layer can return its final internal state(s). The returned states\n",
        "can be used to resume the RNN execution later, or\n",
        "[to initialize another RNN](https://arxiv.org/abs/1409.3215).\n",
        "This setting is commonly used in the\n",
        "encoder-decoder sequence-to-sequence model, where the encoder final state is used as\n",
        "the initial state of the decoder.\n",
        "\n",
        "To configure a RNN layer to return its internal state, set the `return_state` parameter\n",
        "to `True` when creating the layer. Note that `LSTM` has 2 state  tensors, but `GRU`\n",
        "only has one.\n",
        "\n",
        "To configure the initial state of the layer, just call the layer with additional\n",
        "keyword argument `initial_state`.\n",
        "Note that the shape of the state needs to match the unit size of the layer, like in the\n",
        "example below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "o5xZrz25vC6-",
        "outputId": "912b405e-1155-455b-d9b2-280d23e74de1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m64,000\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m128,000\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ encoder (\u001b[38;5;33mLSTM\u001b[0m)            │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │         \u001b[38;5;34m33,024\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│                           │ \u001b[38;5;34m64\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)]       │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder (\u001b[38;5;33mLSTM\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m33,024\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │                        │                │ encoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],         │\n",
              "│                           │                        │                │ encoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │            \u001b[38;5;34m650\u001b[0m │ decoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64,000</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128,000</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)            │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)]       │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │                        │                │ encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],         │\n",
              "│                           │                        │                │ encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ decoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m258,698\u001b[0m (1010.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">258,698</span> (1010.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m258,698\u001b[0m (1010.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">258,698</span> (1010.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "encoder_vocab = 1000\n",
        "decoder_vocab = 2000\n",
        "\n",
        "encoder_input = layers.Input(shape=(None,))\n",
        "encoder_embedded = layers.Embedding(input_dim=encoder_vocab, output_dim=64)(\n",
        "    encoder_input\n",
        ")\n",
        "\n",
        "# Return states in addition to output\n",
        "output, state_h, state_c = layers.LSTM(64, return_state=True, name=\"encoder\")(\n",
        "    encoder_embedded\n",
        ")\n",
        "encoder_state = [state_h, state_c]\n",
        "\n",
        "decoder_input = layers.Input(shape=(None,))\n",
        "decoder_embedded = layers.Embedding(input_dim=decoder_vocab, output_dim=64)(\n",
        "    decoder_input\n",
        ")\n",
        "\n",
        "# Pass the 2 states to a new LSTM layer, as initial state\n",
        "decoder_output = layers.LSTM(64, name=\"decoder\")(\n",
        "    decoder_embedded, initial_state=encoder_state\n",
        ")\n",
        "output = layers.Dense(10)(decoder_output)\n",
        "\n",
        "model = keras.Model([encoder_input, decoder_input], output)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aJqy5yNvC6_"
      },
      "source": [
        "## RNN layers and RNN cells\n",
        "\n",
        "In addition to the built-in RNN layers, the RNN API also provides cell-level APIs.\n",
        "Unlike RNN layers, which processes whole batches of input sequences, the RNN cell only\n",
        "processes a single timestep.\n",
        "\n",
        "The cell is the inside of the `for` loop of a RNN layer. Wrapping a cell inside a\n",
        "`keras.layers.RNN` layer gives you a layer capable of processing batches of\n",
        "sequences, e.g. `RNN(LSTMCell(10))`.\n",
        "\n",
        "Mathematically, `RNN(LSTMCell(10))` produces the same result as `LSTM(10)`. In fact,\n",
        "the implementation of this layer in TF v1.x was just creating the corresponding RNN\n",
        "cell and wrapping it in a RNN layer.  However using the built-in `GRU` and `LSTM`\n",
        "layers enable the use of CuDNN and you may see better performance.\n",
        "\n",
        "There are three built-in RNN cells, each of them corresponding to the matching RNN\n",
        "layer.\n",
        "\n",
        "- `keras.layers.SimpleRNNCell` corresponds to the `SimpleRNN` layer.\n",
        "\n",
        "- `keras.layers.GRUCell` corresponds to the `GRU` layer.\n",
        "\n",
        "- `keras.layers.LSTMCell` corresponds to the `LSTM` layer.\n",
        "\n",
        "The cell abstraction, together with the generic `keras.layers.RNN` class, make it\n",
        "very easy to implement custom RNN architectures for your research."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaAoelKXvC6_"
      },
      "source": [
        "## Cross-batch statefulness\n",
        "\n",
        "When processing very long sequences (possibly infinite), you may want to use the\n",
        "pattern of **cross-batch statefulness**.\n",
        "\n",
        "Normally, the internal state of a RNN layer is reset every time it sees a new batch\n",
        "(i.e. every sample seen by the layer is assumed to be independent of the past). The\n",
        "layer will only maintain a state while processing a given sample.\n",
        "\n",
        "If you have very long sequences though, it is useful to break them into shorter\n",
        "sequences, and to feed these shorter sequences sequentially into a RNN layer without\n",
        "resetting the layer's state. That way, the layer can retain information about the\n",
        "entirety of the sequence, even though it's only seeing one sub-sequence at a time.\n",
        "\n",
        "You can do this by setting `stateful=True` in the constructor.\n",
        "\n",
        "If you have a sequence `s = [t0, t1, ... t1546, t1547]`, you would split it into e.g.\n",
        "\n",
        "```\n",
        "s1 = [t0, t1, ... t100]\n",
        "s2 = [t101, ... t201]\n",
        "...\n",
        "s16 = [t1501, ... t1547]\n",
        "```\n",
        "\n",
        "Then you would process it via:\n",
        "\n",
        "```python\n",
        "lstm_layer = layers.LSTM(64, stateful=True)\n",
        "for s in sub_sequences:\n",
        "  output = lstm_layer(s)\n",
        "```\n",
        "\n",
        "When you want to clear the state, you  can use `layer.reset_states()`.\n",
        "\n",
        "\n",
        "> Note: In this setup, sample `i` in a given batch is assumed to be the continuation of\n",
        "sample `i` in the previous batch. This means that all batches should contain the same\n",
        "number of samples (batch size). E.g. if a batch contains `[sequence_A_from_t0_to_t100,\n",
        " sequence_B_from_t0_to_t100]`, the next batch should contain\n",
        "`[sequence_A_from_t101_to_t200,  sequence_B_from_t101_to_t200]`.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Here is a complete example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GV8Ryxz4vC6_"
      },
      "outputs": [],
      "source": [
        "paragraph1 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "paragraph2 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "paragraph3 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "\n",
        "lstm_layer = layers.LSTM(64, stateful=True)\n",
        "output = lstm_layer(paragraph1)\n",
        "output = lstm_layer(paragraph2)\n",
        "output = lstm_layer(paragraph3)\n",
        "\n",
        "# reset_states() will reset the cached state to the original initial_state.\n",
        "# If no initial_state was provided, zero-states will be used by default.\n",
        "lstm_layer.reset_states()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjm9I1tXvC6_"
      },
      "source": [
        "### RNN State Reuse\n",
        "<a id=\"rnn_state_reuse\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpR8jrg-vC6_"
      },
      "source": [
        "The recorded states of the RNN layer are not included in the `layer.weights()`. If you\n",
        "would like to reuse the state from a RNN layer, you can retrieve the states value by\n",
        "`layer.states` and use it as the\n",
        "initial state for a new layer via the Keras functional API like `new_layer(inputs,\n",
        "initial_state=layer.states)`, or model subclassing.\n",
        "\n",
        "Please also note that sequential model might not be used in this case since it only\n",
        "supports layers with single input and output, the extra input of initial state makes\n",
        "it impossible to use here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fic-DkO9vC7A"
      },
      "outputs": [],
      "source": [
        "paragraph1 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "paragraph2 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "paragraph3 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "\n",
        "lstm_layer = layers.LSTM(64, stateful=True)\n",
        "output = lstm_layer(paragraph1)\n",
        "output = lstm_layer(paragraph2)\n",
        "\n",
        "existing_state = lstm_layer.states\n",
        "\n",
        "new_lstm_layer = layers.LSTM(64)\n",
        "new_output = new_lstm_layer(paragraph3, initial_state=existing_state)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI1QwaAMvC7A"
      },
      "source": [
        "## Bidirectional RNNs\n",
        "\n",
        "For sequences other than time series (e.g. text), it is often the case that a RNN model\n",
        "can perform better if it not only processes sequence from start to end, but also\n",
        "backwards. For example, to predict the next word in a sentence, it is often useful to\n",
        "have the context around the word, not only just the words that come before it.\n",
        "\n",
        "Keras provides an easy API for you to build such bidirectional RNNs: the\n",
        "`keras.layers.Bidirectional` wrapper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HWrfsYOVvC7A",
        "outputId": "bd692870-66e8-4e17-ed9e-5fc945029f4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │          \u001b[38;5;34m38,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m41,216\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">38,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m80,266\u001b[0m (313.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80,266</span> (313.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m80,266\u001b[0m (313.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80,266</span> (313.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add(\n",
        "    layers.Bidirectional(layers.LSTM(64, return_sequences=True), input_shape=(5, 10))\n",
        ")\n",
        "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oxaNKASvC7A"
      },
      "source": [
        "Under the hood, `Bidirectional` will copy the RNN layer passed in, and flip the\n",
        "`go_backwards` field of the newly copied layer, so that it will process the inputs in\n",
        "reverse order.\n",
        "\n",
        "The output of the `Bidirectional` RNN will be, by default, the concatenation of the forward layer\n",
        "output and the backward layer output. If you need a different merging behavior, e.g.\n",
        "concatenation, change the `merge_mode` parameter in the `Bidirectional` wrapper\n",
        "constructor. For more details about `Bidirectional`, please check\n",
        "[the API docs](https://keras.io/api/layers/recurrent_layers/bidirectional/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXmXmIaBvC7A"
      },
      "source": [
        "## Performance optimization and CuDNN kernels\n",
        "\n",
        "In TensorFlow 2.0, the built-in LSTM and GRU layers have been updated to leverage CuDNN\n",
        "kernels by default when a GPU is available. With this change, the prior\n",
        "`keras.layers.CuDNNLSTM/CuDNNGRU` layers have been deprecated, and you can build your\n",
        "model without worrying about the hardware it will run on.\n",
        "\n",
        "Since the CuDNN kernel is built with certain assumptions, this means the layer **will\n",
        "not be able to use the CuDNN kernel if you change the defaults of the built-in LSTM or\n",
        "GRU layers**. E.g.:\n",
        "\n",
        "- Changing the `activation` function from `tanh` to something else.\n",
        "- Changing the `recurrent_activation` function from `sigmoid` to something else.\n",
        "- Using `recurrent_dropout` > 0.\n",
        "- Setting `unroll` to True, which forces LSTM/GRU to decompose the inner\n",
        "`tf.while_loop` into an unrolled `for` loop.\n",
        "- Setting `use_bias` to False.\n",
        "- Using masking when the input data is not strictly right padded (if the mask\n",
        "corresponds to strictly right padded data, CuDNN can still be used. This is the most\n",
        "common case).\n",
        "\n",
        "For the detailed list of constraints, please see the documentation for the\n",
        "[LSTM](https://keras.io/api/layers/recurrent_layers/lstm/) and\n",
        "[GRU](https://keras.io/api/layers/recurrent_layers/gru/) layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r197LkkRvC7B"
      },
      "source": [
        "### Using CuDNN kernels when available\n",
        "\n",
        "Let's build a simple LSTM model to demonstrate the performance difference.\n",
        "\n",
        "We'll use as input sequences the sequence of rows of MNIST digits (treating each row of\n",
        "pixels as a timestep), and we'll predict the digit's label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mTdwghC7vC7B"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "# Each MNIST image batch is a tensor of shape (batch_size, 28, 28).\n",
        "# Each input sequence will be of size (28, 28) (height is treated like time).\n",
        "input_dim = 28\n",
        "\n",
        "units = 64\n",
        "output_size = 10  # labels are from 0 to 9\n",
        "\n",
        "\n",
        "# Build the RNN model\n",
        "def build_model(allow_cudnn_kernel=True):\n",
        "    # CuDNN is only available at the layer level, and not at the cell level.\n",
        "    # This means `LSTM(units)` will use the CuDNN kernel,\n",
        "    # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
        "    if allow_cudnn_kernel:\n",
        "        # The LSTM layer with default options uses CuDNN.\n",
        "        lstm_layer = keras.layers.LSTM(units, input_shape=(None, input_dim))\n",
        "    else:\n",
        "        # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\n",
        "        lstm_layer = keras.layers.RNN(\n",
        "            keras.layers.LSTMCell(units), input_shape=(None, input_dim)\n",
        "        )\n",
        "    model = keras.models.Sequential(\n",
        "        [\n",
        "            lstm_layer,\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.Dense(output_size),\n",
        "        ]\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqZTgtaGvC7B"
      },
      "source": [
        "Let's load the MNIST dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rZYLAc8dvC7B",
        "outputId": "200bfd79-6bd8-4b0f-ac2e-6dc5a06d887f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "mnist = keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "sample, sample_label = x_train[0], y_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af04E8y0vC7B"
      },
      "source": [
        "Let's create a model instance and train it.\n",
        "\n",
        "We choose `sparse_categorical_crossentropy` as the loss function for the model. The\n",
        "output of the model has shape of `[batch_size, 10]`. The target for the model is an\n",
        "integer vector, each of the integer is in the range of 0 to 9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GoPK-HLIvC7C",
        "outputId": "baff2c7e-0241-48b3-c3df-80151a39fd99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5882 - loss: 1.2794 - val_accuracy: 0.8463 - val_loss: 0.4902\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c10fad7ee00>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model = build_model(allow_cudnn_kernel=True)\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=\"sgd\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhHdKtIvvC7C"
      },
      "source": [
        "Now, let's compare to a model that does not use the CuDNN kernel:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0FTZcMq6vC7C",
        "outputId": "aa43d6f1-603e-41ec-be02-4aebd8c7745a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.8688 - loss: 0.4340 - val_accuracy: 0.8918 - val_loss: 0.3303\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c10fb332650>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "noncudnn_model = build_model(allow_cudnn_kernel=False)\n",
        "noncudnn_model.set_weights(model.get_weights())\n",
        "noncudnn_model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=\"sgd\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "noncudnn_model.fit(\n",
        "    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpY0ir3vvC7C"
      },
      "source": [
        "When running on a machine with a NVIDIA GPU and CuDNN installed,\n",
        "the model built with CuDNN is much faster to train compared to the\n",
        "model that uses the regular TensorFlow kernel.\n",
        "\n",
        "The same CuDNN-enabled model can also be used to run inference in a CPU-only\n",
        "environment. The `tf.device` annotation below is just forcing the device placement.\n",
        "The model will run on CPU by default if no GPU is available.\n",
        "\n",
        "You simply don't have to worry about the hardware you're running on anymore. Isn't that\n",
        "pretty cool?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RR8j-NTIvC7C",
        "outputId": "8269b11d-26da-4817-b498-1939c083c0bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted result is: [3], target result is: 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with tf.device(\"CPU:0\"):\n",
        "    cpu_model = build_model(allow_cudnn_kernel=True)\n",
        "    cpu_model.set_weights(model.get_weights())\n",
        "    result = tf.argmax(cpu_model.predict_on_batch(tf.expand_dims(sample, 0)), axis=1)\n",
        "    print(\n",
        "        \"Predicted result is: %s, target result is: %s\" % (result.numpy(), sample_label)\n",
        "    )\n",
        "    plt.imshow(sample, cmap=plt.get_cmap(\"gray\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeM_sg02vC7C"
      },
      "source": [
        "## RNNs with list/dict inputs, or nested inputs\n",
        "\n",
        "Nested structures allow implementers to include more information within a single\n",
        "timestep. For example, a video frame could have audio and video input at the same\n",
        "time. The data shape in this case could be:\n",
        "\n",
        "`[batch, timestep, {\"video\": [height, width, channel], \"audio\": [frequency]}]`\n",
        "\n",
        "In another example, handwriting data could have both coordinates x and y for the\n",
        "current position of the pen, as well as pressure information. So the data\n",
        "representation could be:\n",
        "\n",
        "`[batch, timestep, {\"location\": [x, y], \"pressure\": [force]}]`\n",
        "\n",
        "The following code provides an example of how to build a custom RNN cell that accepts\n",
        "such structured inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2xF7NktvC7D"
      },
      "source": [
        "### Define a custom cell that supports nested input/output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBTpB-YmvC7D"
      },
      "source": [
        "See [Making new Layers & Models via subclassing](/guides/making_new_layers_and_models_via_subclassing/)\n",
        "for details on writing your own layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bixxYEvqvC7D"
      },
      "outputs": [],
      "source": [
        "\n",
        "@keras.saving.register_keras_serializable()\n",
        "class NestedCell(keras.layers.Layer):\n",
        "    def __init__(self, unit_1, unit_2, unit_3, **kwargs):\n",
        "        self.unit_1 = unit_1\n",
        "        self.unit_2 = unit_2\n",
        "        self.unit_3 = unit_3\n",
        "        self.state_size = [tf.TensorShape([unit_1]), tf.TensorShape([unit_2, unit_3])]\n",
        "        self.output_size = [tf.TensorShape([unit_1]), tf.TensorShape([unit_2, unit_3])]\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shapes):\n",
        "        # expect input_shape to contain 2 items, [(batch, i1), (batch, i2, i3)]\n",
        "        i1 = input_shapes[0][1]\n",
        "        i2 = input_shapes[1][1]\n",
        "        i3 = input_shapes[1][2]\n",
        "\n",
        "        self.kernel_1 = self.add_weight(\n",
        "            shape=(i1, self.unit_1), initializer=\"uniform\", name=\"kernel_1\"\n",
        "        )\n",
        "        self.kernel_2_3 = self.add_weight(\n",
        "            shape=(i2, i3, self.unit_2, self.unit_3),\n",
        "            initializer=\"uniform\",\n",
        "            name=\"kernel_2_3\",\n",
        "        )\n",
        "\n",
        "    def call(self, inputs, states):\n",
        "        # inputs should be in [(batch, input_1), (batch, input_2, input_3)]\n",
        "        # state should be in shape [(batch, unit_1), (batch, unit_2, unit_3)]\n",
        "        input_1, input_2 = tf.nest.flatten(inputs)\n",
        "        s1, s2 = states\n",
        "\n",
        "        output_1 = tf.matmul(input_1, self.kernel_1)\n",
        "        output_2_3 = tf.einsum(\"bij,ijkl->bkl\", input_2, self.kernel_2_3)\n",
        "        state_1 = s1 + output_1\n",
        "        state_2_3 = s2 + output_2_3\n",
        "\n",
        "        output = (output_1, output_2_3)\n",
        "        new_states = (state_1, state_2_3)\n",
        "\n",
        "        return output, new_states\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\"unit_1\": self.unit_1, \"unit_2\": self.unit_2, \"unit_3\": self.unit_3}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6H50ZyXvC7D"
      },
      "source": [
        "### Build a RNN model with nested input/output\n",
        "\n",
        "Let's build a Keras model that uses a `keras.layers.RNN` layer and the custom cell\n",
        "we just defined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LmjF6TomvC7D",
        "outputId": "544674aa-a768-42b8-be69-13772def746b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "tuple index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-e123107f7ded>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Instead of: outputs = rnn((input_1, input_2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Pass inputs as a list:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-fee25f2659c3>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shapes)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# expect input_shape to contain 2 items, [(batch, i1), (batch, i2, i3)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mi2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mi3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ],
      "source": [
        "unit_1 = 10\n",
        "unit_2 = 20\n",
        "unit_3 = 30\n",
        "\n",
        "i1 = 32\n",
        "i2 = 64\n",
        "i3 = 32\n",
        "batch_size = 64\n",
        "num_batches = 10\n",
        "timestep = 50\n",
        "\n",
        "cell = NestedCell(unit_1, unit_2, unit_3)\n",
        "rnn = keras.layers.RNN(cell)\n",
        "\n",
        "# ... (previous code)\n",
        "\n",
        "# Build the RNN model\n",
        "input_1 = keras.Input((None, i1))\n",
        "input_2 = keras.Input((None, i2, i3))\n",
        "\n",
        "# Instead of: outputs = rnn((input_1, input_2))\n",
        "# Pass inputs as a list:\n",
        "outputs = rnn([input_1, input_2])\n",
        "\n",
        "model = keras.models.Model([input_1, input_2], outputs)\n",
        "\n",
        "# ... (rest of the code)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58ZQko6AvC7E"
      },
      "source": [
        "### Train the model with randomly generated data\n",
        "\n",
        "Since there isn't a good candidate dataset for this model, we use random Numpy data for\n",
        "demonstration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "jMSJls9DvC7I",
        "outputId": "21505250-ac8a-4103-82b9-f0effb62e814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Argument `output` must have rank (ndim) `target.ndim - 1`. Received: target.shape=(64, 10), output.shape=(64, 10)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-dd3b8c092627>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtarget_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtarget_1_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_2_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py\u001b[0m in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    650\u001b[0m         )\n\u001b[1;32m    651\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    653\u001b[0m             \u001b[0;34m\"Argument `output` must have rank (ndim) `target.ndim - 1`. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;34m\"Received: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Argument `output` must have rank (ndim) `target.ndim - 1`. Received: target.shape=(64, 10), output.shape=(64, 10)"
          ]
        }
      ],
      "source": [
        "input_1_data = np.random.random((batch_size * num_batches, timestep, i1))\n",
        "input_2_data = np.random.random((batch_size * num_batches, timestep, i2, i3))\n",
        "target_1_data = np.random.random((batch_size * num_batches, unit_1))\n",
        "target_2_data = np.random.random((batch_size * num_batches, unit_2, unit_3))\n",
        "input_data = [input_1_data, input_2_data]\n",
        "target_data = [target_1_data, target_2_data]\n",
        "\n",
        "model.fit(input_data, target_data, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om0KKOFDvC7J"
      },
      "source": [
        "With the Keras `keras.layers.RNN` layer, You are only expected to define the math\n",
        "logic for individual step within the sequence, and the `keras.layers.RNN` layer\n",
        "will handle the sequence iteration for you. It's an incredibly powerful way to quickly\n",
        "prototype new kinds of RNNs (e.g. a LSTM variant).\n",
        "\n",
        "For more details, please visit the [API docs](https://keras.io/api/layers/recurrent_layers/rnn/)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "working_with_rnns",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}